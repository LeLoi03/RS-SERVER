"""
================================================================================
Pipeline Step 1: User Clustering
================================================================================
"""

import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from typing import Dict, Any
# Kh√¥ng c·∫ßn import config.config n·ªØa v√¨ config s·∫Ω ƒë∆∞·ª£c truy·ªÅn v√†o
from src.utils.file_handlers import save_pickle, load_pickle
from src.utils.live_logger import LiveLogger
from config import config as static_config # Import ƒë·ªÉ l·∫•y ƒë∆∞·ªùng d·∫´n artifact

# THAY ƒê·ªîI: H√†m b√¢y gi·ªù nh·∫≠n DataFrame v√† m·ªôt dict c·∫•u h√¨nh
def run_clustering_pipeline(df: pd.DataFrame, config_data: Dict[str, Any]) -> bool:
    """
    Th·ª±c hi·ªán b∆∞·ªõc ph√¢n c·ª•m ng∆∞·ªùi d√πng c·ªßa pipeline.
    H√†m n√†y nh·∫≠n m·ªôt DataFrame, nh√≥m ng∆∞·ªùi d√πng th√†nh c√°c c·ª•m d·ª±a tr√™n
    h√†nh vi ƒë√°nh gi√° c·ªßa h·ªç b·∫±ng K-Means v·ªõi kh·ªüi t·∫°o ICR, v√† l∆∞u k·∫øt qu·∫£.

    Args:
        df (pd.DataFrame): DataFrame ngu·ªìn ch·ª©a d·ªØ li·ªáu ph·∫£n h·ªìi c·ªßa ng∆∞·ªùi d√πng.
        config_data (Dict[str, Any]): M·ªôt dictionary ch·ª©a c√°c tham s·ªë c·∫•u h√¨nh
                                      cho l·∫ßn ch·∫°y pipeline n√†y (v√≠ d·ª•: NUM_CLUSTERS).

    Returns:
        bool: True n·∫øu b∆∞·ªõc pipeline ho√†n th√†nh th√†nh c√¥ng, False n·∫øu ng∆∞·ª£c l·∫°i.
    """
    try:
        # --- 1. Process Input Data ---
        LiveLogger.log("‚úÖ Source data received as DataFrame.")
        if df.empty:
            LiveLogger.log("‚ùå Error: Source DataFrame is empty.")
            return False
        LiveLogger.log(f"   - Processing {len(df)} reviews.")

        # --- 2. Create User-Item Matrix and Mappings ---
        LiveLogger.log("üõ†Ô∏è  Creating user-item rating matrix and mappings...")
        users = df['user_id'].unique()
        items = df['conference_key'].unique()

        user_map = {uid: i for i, uid in enumerate(users)}
        item_map = {iid: i for i, iid in enumerate(items)}
        rev_user_map = {i: uid for uid, i in user_map.items()}
        rev_item_map = {i: iid for iid, i in item_map.items()}

        rating_matrix = np.zeros((len(users), len(items)))
        for _, row in df.iterrows():
            user_idx = user_map.get(row['user_id'])
            item_idx = item_map.get(row['conference_key'])
            if user_idx is not None and item_idx is not None:
                rating_matrix[user_idx, item_idx] = row['rating']
        LiveLogger.log(f"   - Matrix created with shape: {rating_matrix.shape} (Users x Items)")

        # --- 3. Apply K-Means with ICR Initialization ---
        LiveLogger.log("üß† Applying K-Means clustering with ICR initialization...")

        num_ratings_per_user = np.sum(rating_matrix != 0, axis=1)

        # THAY ƒê·ªîI: S·ª≠ d·ª•ng gi√° tr·ªã NUM_CLUSTERS t·ª´ dict config_data ƒë∆∞·ª£c truy·ªÅn v√†o
        num_clusters_from_config = config_data['NUM_CLUSTERS']

        # ƒê·∫£m b·∫£o kh√¥ng l·∫•y nhi·ªÅu centroid h∆°n s·ªë l∆∞·ª£ng user
        num_centroids = min(num_clusters_from_config, len(users))
        if num_centroids < num_clusters_from_config:
            LiveLogger.log(f"   - Warning: Number of users ({len(users)}) is less than NUM_CLUSTERS ({num_clusters_from_config}). Using {num_centroids} clusters instead.")

        centroid_indices = np.argsort(num_ratings_per_user)[-num_centroids:]
        initial_centroids = rating_matrix[centroid_indices]
        LiveLogger.log(f"   - Selected {len(initial_centroids)} initial centroids based on user activity (ICR).")

        user_means = np.true_divide(rating_matrix.sum(1), (rating_matrix != 0).sum(1))
        user_means[np.isnan(user_means)] = 0
        filled_matrix = np.where(rating_matrix == 0, user_means[:, np.newaxis], rating_matrix)

        kmeans = KMeans(
            n_clusters=num_centroids,
            init=initial_centroids,
            n_init=1,
            random_state=42
        )
        labels = kmeans.fit_predict(filled_matrix)
        LiveLogger.log(f"   - Successfully assigned {len(users)} users to {num_centroids} clusters.")

        # --- 4. Format and Save Artifacts ---
        # S·ª≠ d·ª•ng ƒë∆∞·ªùng d·∫´n tƒ©nh t·ª´ static_config
        LiveLogger.log(f"üíæ Formatting and saving clustering artifacts to '{static_config.CLUSTERING_ARTIFACT_PATH.name}'...")

        clusters = {i: [] for i in range(num_centroids)}
        for user_idx, cluster_label in enumerate(labels):
            original_user_id = rev_user_map[user_idx]
            clusters[cluster_label].append(original_user_id)

        clustering_artifacts = {
            "clusters": clusters,
            "user_map": user_map,
            "item_map": item_map,
            "rev_user_map": rev_user_map,
            "rev_item_map": rev_item_map
        }

        save_pickle(clustering_artifacts, static_config.CLUSTERING_ARTIFACT_PATH)
        LiveLogger.log(f"   - Artifact saved successfully.")

        # --- 5. Log Cluster Statistics for Verification ---
        LiveLogger.log("\n--- Clustering Statistics ---")
        cluster_stats = pd.DataFrame({
            "Cluster ID": list(clusters.keys()),
            "Number of Users": [len(users) for users in clusters.values()]
        }).sort_values(by="Number of Users", ascending=False)

        stats_string = cluster_stats.to_markdown(index=False)
        LiveLogger.log(stats_string)

        return True

    except Exception as e:
        LiveLogger.log(f"‚ùå An unexpected error occurred in the clustering pipeline: {e}")
        return False

# THAY ƒê·ªîI: C·∫≠p nh·∫≠t kh·ªëi ch·∫°y standalone ƒë·ªÉ m√¥ ph·ªèng vi·ªác truy·ªÅn config
if __name__ == '__main__':
    class ConsoleLogger:
        @staticmethod
        def log(message): print(message)
        @staticmethod
        def start_progress(description, total): print(f"--- Starting Progress: {description} ---")
        @staticmethod
        def update_progress(current): pass

    import sys
    sys.modules['src.utils.live_logger'] = type('LiveLoggerMock', (), {'LiveLogger': ConsoleLogger})
    from src.utils.live_logger import LiveLogger

    # Import data loader v√† config loader ƒë·ªÉ ch·∫°y th·ª≠ nghi·ªám
    from utils.feedbacks_data_loader import fetch_and_prepare_data
    from config.config import get_pipeline_config

    print("--- Running Clustering Pipeline in Standalone Mode ---")
    try:
        print("Step 0a: Fetching data for standalone test...")
        source_df = fetch_and_prepare_data(force_fetch=False)

        print("Step 0b: Loading pipeline configuration...")
        # M√¥ ph·ªèng orchestrator: t·∫£i config tr∆∞·ªõc khi ch·∫°y
        test_config = get_pipeline_config()
        print(f"   - Loaded config with NUM_CLUSTERS = {test_config['NUM_CLUSTERS']}")

        if source_df is not None and not source_df.empty:
            print("\nStep 1: Running clustering logic...")
            # Truy·ªÅn c·∫£ DataFrame v√† config v√†o h√†m
            success = run_clustering_pipeline(source_df, test_config)
            if success:
                print("\n‚úÖ Clustering pipeline completed successfully in standalone mode.")
            else:
                print("\n‚ùå Clustering pipeline failed in standalone mode.")
        else:
            print("‚ùå Failed to fetch or prepare data. Halting standalone test.")

    except Exception as e:
        print(f"An error occurred during standalone execution: {e}")

    print("--- Standalone run finished ---")
